/data/hzy/lvm4-ts/IMTS/run_models.py
2025-04-29 07:44:15
run_models.py --model VisionTS-B --dataset mimic --state def --history 24 --patience 15 --batch_size 12 --lr 1e-4 --patch_size 8 --stride 8 --nhead 1 --tf_layer 1 --nlayer 3 --te_dim 40 --node_dim 40 --hid_dim 40 --mask_ratio 0.4 --train_mode fine-tune --finetune_type wo_ssl_ft --pretrain_weights_dir /data/hzy/lvm4-ts/IMTS/logs/mimic/mimic_fewshot0.5_pretrain/pretrain_weights/Exp66129_VisionTS-B_hid_dim40_te_dim40_node_dim40_mask_ratio0.4_stride8.0_patchsize8.0_seed1_nlayer3_best.pth --few_shot_ratio 0.5 --seed 2 --gpu 2 --log_dir mimic_fewshot0.5_finetune
Namespace(state='def', n=100000000, hop=1, nhead=1, tf_layer=1, nlayer=3, epoch=1000, patience=15, history=24, patch_size=8.0, stride=8.0, logmode='a', lr=0.0001, w_decay=0.0, batch_size=12, load=None, seed=2, dataset='mimic', log_dir='mimic_fewshot0.5_finetune', pretrain_weights_dir='/data/hzy/lvm4-ts/IMTS/logs/mimic/mimic_fewshot0.5_pretrain/pretrain_weights/Exp66129_VisionTS-B_hid_dim40_te_dim40_node_dim40_mask_ratio0.4_stride8.0_patchsize8.0_seed1_nlayer3_best.pth', quantization=0.0, model='VisionTS-B', mask_flag=False, hid_dim=40, te_dim=40, node_dim=40, gpu='2', log_suffix='', periodicity=None, mask_ratio=0.4, train_mode='fine-tune', TTT=False, ttt_iter=None, ttt_lr=None, apply_lora=False, lora_r=8, lora_alpha=1, lora_dropout=0.0, merge_weights=False, finetune_type='wo_ssl_ft', encoder_only=False, few_shot_ratio=0.5, no_vision_pre=False, wo_gcn=False, npatch=3, world_size=1, device=device(type='cuda'), ft_type='full', arch='mae_base', vm_pretrained=True, vm_ckpt='./ckpt/', interpolation='bilinear', norm_const=0.4, align_const=0.4, grid_method='linear', if_patch=True, pred_window=24, npred_patch=3, ndim=96)
- Epoch 000, ExpID 98600
Train - Loss (one batch): 0.01638
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01727, 0.01727, 0.13143, 0.07330, 125.48%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.01587, 0.01587, 0.12597, 0.07074, 94.93%
Time spent: 285.67s
- Epoch 001, ExpID 98600
Train - Loss (one batch): 0.00688
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01681, 0.01681, 0.12966, 0.07356, 118.13%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.01564, 0.01564, 0.12504, 0.07117, 89.98%
Time spent: 286.87s
- Epoch 002, ExpID 98600
Train - Loss (one batch): 0.01458
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01671, 0.01671, 0.12925, 0.07238, 121.71%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 2, 0.01554, 0.01554, 0.12466, 0.06977, 91.16%
Time spent: 287.53s
- Epoch 003, ExpID 98600
Train - Loss (one batch): 0.00808
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01659, 0.01659, 0.12879, 0.07241, 116.74%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.01548, 0.01548, 0.12442, 0.06997, 89.02%
Time spent: 283.98s
- Epoch 004, ExpID 98600
Train - Loss (one batch): 0.01061
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01683, 0.01683, 0.12974, 0.07208, 120.61%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.01548, 0.01548, 0.12442, 0.06997, 89.02%
Time spent: 251.08s
- Epoch 005, ExpID 98600
Train - Loss (one batch): 0.00768
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01676, 0.01676, 0.12946, 0.07382, 138.50%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.01548, 0.01548, 0.12442, 0.06997, 89.02%
Time spent: 244.80s
- Epoch 006, ExpID 98600
Train - Loss (one batch): 0.01836
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01650, 0.01650, 0.12847, 0.07194, 120.20%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.01531, 0.01531, 0.12373, 0.06923, 93.62%
Time spent: 284.87s
- Epoch 007, ExpID 98600
Train - Loss (one batch): 0.01734
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01611, 0.01611, 0.12694, 0.06916, 105.78%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 7, 0.01501, 0.01501, 0.12250, 0.06664, 81.55%
Time spent: 287.30s
- Epoch 008, ExpID 98600
Train - Loss (one batch): 0.01148
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01627, 0.01627, 0.12754, 0.07085, 117.39%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 7, 0.01501, 0.01501, 0.12250, 0.06664, 81.55%
Time spent: 249.95s
- Epoch 009, ExpID 98600
Train - Loss (one batch): 0.01017
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01619, 0.01619, 0.12726, 0.07160, 117.08%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 7, 0.01501, 0.01501, 0.12250, 0.06664, 81.55%
Time spent: 244.38s
- Epoch 010, ExpID 98600
Train - Loss (one batch): 0.00866
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01611, 0.01611, 0.12693, 0.06941, 104.79%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.01493, 0.01493, 0.12218, 0.06678, 83.00%
Time spent: 271.21s
- Epoch 011, ExpID 98600
Train - Loss (one batch): 0.01287
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01598, 0.01598, 0.12641, 0.06956, 109.08%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 11, 0.01478, 0.01478, 0.12156, 0.06686, 85.24%
Time spent: 298.41s
- Epoch 012, ExpID 98600
Train - Loss (one batch): 0.01367
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01606, 0.01606, 0.12675, 0.06975, 109.84%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 11, 0.01478, 0.01478, 0.12156, 0.06686, 85.24%
Time spent: 251.81s
- Epoch 013, ExpID 98600
Train - Loss (one batch): 0.01381
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01511, 0.01511, 0.12294, 0.06833, 98.62%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.01427, 0.01427, 0.11946, 0.06577, 84.11%
Time spent: 293.17s
- Epoch 014, ExpID 98600
Train - Loss (one batch): 0.01910
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01553, 0.01553, 0.12460, 0.06952, 112.75%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.01427, 0.01427, 0.11946, 0.06577, 84.11%
Time spent: 241.90s
- Epoch 015, ExpID 98600
Train - Loss (one batch): 0.00536
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01606, 0.01606, 0.12673, 0.06973, 108.81%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.01427, 0.01427, 0.11946, 0.06577, 84.11%
Time spent: 242.08s
- Epoch 016, ExpID 98600
Train - Loss (one batch): 0.01534
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01578, 0.01578, 0.12563, 0.06928, 106.67%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.01427, 0.01427, 0.11946, 0.06577, 84.11%
Time spent: 252.58s
- Epoch 017, ExpID 98600
Train - Loss (one batch): 0.01105
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01554, 0.01554, 0.12467, 0.06878, 105.01%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.01427, 0.01427, 0.11946, 0.06577, 84.11%
Time spent: 249.98s
- Epoch 018, ExpID 98600
Train - Loss (one batch): 0.01014
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01585, 0.01585, 0.12591, 0.06939, 105.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.01427, 0.01427, 0.11946, 0.06577, 84.11%
Time spent: 243.18s
- Epoch 019, ExpID 98600
Train - Loss (one batch): 0.00604
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01572, 0.01572, 0.12537, 0.06857, 98.20%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.01427, 0.01427, 0.11946, 0.06577, 84.11%
Time spent: 251.55s
- Epoch 020, ExpID 98600
Train - Loss (one batch): 0.00634
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01538, 0.01538, 0.12402, 0.06873, 101.14%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.01427, 0.01427, 0.11946, 0.06577, 84.11%
Time spent: 245.84s
- Epoch 021, ExpID 98600
Train - Loss (one batch): 0.01181
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01540, 0.01540, 0.12410, 0.06959, 113.51%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.01427, 0.01427, 0.11946, 0.06577, 84.11%
Time spent: 249.03s
- Epoch 022, ExpID 98600
Train - Loss (one batch): 0.00818
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01596, 0.01596, 0.12632, 0.07002, 117.71%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.01427, 0.01427, 0.11946, 0.06577, 84.11%
Time spent: 250.45s
- Epoch 023, ExpID 98600
Train - Loss (one batch): 0.01655
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01536, 0.01536, 0.12393, 0.06815, 105.44%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.01427, 0.01427, 0.11946, 0.06577, 84.11%
Time spent: 247.36s
- Epoch 024, ExpID 98600
Train - Loss (one batch): 0.00614
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01553, 0.01553, 0.12461, 0.07057, 113.72%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.01427, 0.01427, 0.11946, 0.06577, 84.11%
Time spent: 246.24s
- Epoch 025, ExpID 98600
Train - Loss (one batch): 0.00484
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01554, 0.01554, 0.12465, 0.06817, 101.37%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.01427, 0.01427, 0.11946, 0.06577, 84.11%
Time spent: 235.73s
- Epoch 026, ExpID 98600
Train - Loss (one batch): 0.01614
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01553, 0.01553, 0.12463, 0.07014, 112.60%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.01427, 0.01427, 0.11946, 0.06577, 84.11%
Time spent: 239.61s
- Epoch 027, ExpID 98600
Train - Loss (one batch): 0.01500
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01568, 0.01568, 0.12522, 0.06797, 98.44%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.01427, 0.01427, 0.11946, 0.06577, 84.11%
Time spent: 244.90s
- Epoch 028, ExpID 98600
Train - Loss (one batch): 0.01599
Val - Loss, MSE, RMSE, MAE, MAPE: 0.01578, 0.01578, 0.12564, 0.07059, 112.90%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.01427, 0.01427, 0.11946, 0.06577, 84.11%
Time spent: 250.93s
