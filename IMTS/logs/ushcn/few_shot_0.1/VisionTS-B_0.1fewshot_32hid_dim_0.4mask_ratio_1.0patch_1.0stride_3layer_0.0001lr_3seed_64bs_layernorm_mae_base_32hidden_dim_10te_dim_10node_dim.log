/root/lvm4-ts/IMTS/run_models.py
2025-01-25 00:33:54
run_models.py --model VisionTS-B --dataset ushcn --state def --history 24 --patience 15 --batch_size 64 --lr 1e-4 --patch_size 1 --stride 1 --nhead 1 --tf_layer 1 --nlayer 3 --te_dim 10 --node_dim 10 --hid_dim 32 --mask_ratio 0.4 --train_mode fine-tune --finetune_type norm --pretrain_weights_dir /root/lvm4-ts/IMTS/logs/ushcn/fewshot_pretrain/pretrain_weights/Exp95610_VisionTS-B_hid_dim32_te_dim10_node_dim10_mask_ratio0.4_stride1.0_patchsize1.0_seed1_nlayer3_best.pth --few_shot_ratio 0.1 --seed 3 --gpu 1 --log_dir few_shot_0.1
Namespace(state='def', n=100000000, hop=1, nhead=1, tf_layer=1, nlayer=3, epoch=1000, patience=15, history=24, patch_size=1.0, stride=1.0, logmode='a', lr=0.0001, w_decay=0.0, batch_size=64, load=None, seed=3, dataset='ushcn', log_dir='few_shot_0.1', pretrain_weights_dir='/root/lvm4-ts/IMTS/logs/ushcn/fewshot_pretrain/pretrain_weights/Exp95610_VisionTS-B_hid_dim32_te_dim10_node_dim10_mask_ratio0.4_stride1.0_patchsize1.0_seed1_nlayer3_best.pth', quantization=0.0, model='VisionTS-B', mask_flag=False, hid_dim=32, te_dim=10, node_dim=10, gpu='1', log_suffix='', periodicity=None, mask_ratio=0.4, train_mode='fine-tune', TTT=False, ttt_iter=None, ttt_lr=None, apply_lora=False, lora_r=8, lora_alpha=1, lora_dropout=0.0, merge_weights=False, finetune_type='norm', encoder_only=False, few_shot_ratio=0.1, npatch=24, world_size=1, device=device(type='cuda'), ft_type='full', arch='mae_base', vm_pretrained=True, vm_ckpt='./ckpt/', interpolation='bilinear', norm_const=0.4, align_const=0.4, grid_method='linear', if_patch=True, n_months=48, pred_window=1, npred_patch=1, ndim=5)
- Epoch 000, ExpID 17642
Train - Loss (one batch): 0.17859
Val - Loss, MSE, RMSE, MAE, MAPE: 0.90883, 0.90883, 0.95333, 0.34060, -54.78%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.52192, 0.52192, 0.72244, 0.31370, -51.94%
Time spent: 35.91s
- Epoch 001, ExpID 17642
Train - Loss (one batch): 0.28543
Val - Loss, MSE, RMSE, MAE, MAPE: 0.90494, 0.90494, 0.95128, 0.33886, -54.45%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.51805, 0.51805, 0.71975, 0.31187, -51.81%
Time spent: 34.98s
- Epoch 002, ExpID 17642
Train - Loss (one batch): 0.27302
Val - Loss, MSE, RMSE, MAE, MAPE: 0.90815, 0.90815, 0.95297, 0.33273, -49.29%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.51805, 0.51805, 0.71975, 0.31187, -51.81%
Time spent: 23.61s
- Epoch 003, ExpID 17642
Train - Loss (one batch): 0.41187
Val - Loss, MSE, RMSE, MAE, MAPE: 0.90110, 0.90110, 0.94926, 0.34117, -57.05%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.51512, 0.51512, 0.71772, 0.31442, -54.60%
Time spent: 35.36s
- Epoch 004, ExpID 17642
Train - Loss (one batch): 0.48441
Val - Loss, MSE, RMSE, MAE, MAPE: 0.90087, 0.90087, 0.94914, 0.33655, -53.76%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.51431, 0.51431, 0.71716, 0.30988, -51.47%
Time spent: 34.63s
- Epoch 005, ExpID 17642
Train - Loss (one batch): 0.26201
Val - Loss, MSE, RMSE, MAE, MAPE: 0.89745, 0.89745, 0.94734, 0.33750, -55.34%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 5, 0.51204, 0.51204, 0.71557, 0.31032, -52.76%
Time spent: 36.08s
- Epoch 006, ExpID 17642
Train - Loss (one batch): 0.20909
Val - Loss, MSE, RMSE, MAE, MAPE: 0.89531, 0.89531, 0.94621, 0.33963, -56.61%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.51164, 0.51164, 0.71529, 0.31254, -54.25%
Time spent: 34.79s
- Epoch 007, ExpID 17642
Train - Loss (one batch): 1.25038
Val - Loss, MSE, RMSE, MAE, MAPE: 0.89925, 0.89925, 0.94829, 0.33969, -57.22%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.51164, 0.51164, 0.71529, 0.31254, -54.25%
Time spent: 23.72s
- Epoch 008, ExpID 17642
Train - Loss (one batch): 0.21271
Val - Loss, MSE, RMSE, MAE, MAPE: 0.89598, 0.89598, 0.94656, 0.33250, -51.82%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.51164, 0.51164, 0.71529, 0.31254, -54.25%
Time spent: 23.45s
- Epoch 009, ExpID 17642
Train - Loss (one batch): 0.37289
Val - Loss, MSE, RMSE, MAE, MAPE: 0.89566, 0.89566, 0.94640, 0.33290, -51.62%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.51164, 0.51164, 0.71529, 0.31254, -54.25%
Time spent: 23.16s
- Epoch 010, ExpID 17642
Train - Loss (one batch): 0.15209
Val - Loss, MSE, RMSE, MAE, MAPE: 0.89588, 0.89588, 0.94651, 0.32936, -48.98%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.51164, 0.51164, 0.71529, 0.31254, -54.25%
Time spent: 24.87s
- Epoch 011, ExpID 17642
Train - Loss (one batch): 0.22442
Val - Loss, MSE, RMSE, MAE, MAPE: 0.89514, 0.89514, 0.94612, 0.33185, -53.02%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 11, 0.51131, 0.51131, 0.71506, 0.30469, -50.52%
Time spent: 35.44s
- Epoch 012, ExpID 17642
Train - Loss (one batch): 0.19133
Val - Loss, MSE, RMSE, MAE, MAPE: 0.89341, 0.89341, 0.94520, 0.33494, -54.78%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 12, 0.50969, 0.50969, 0.71393, 0.30809, -52.74%
Time spent: 34.28s
- Epoch 013, ExpID 17642
Train - Loss (one batch): 0.27234
Val - Loss, MSE, RMSE, MAE, MAPE: 0.89126, 0.89126, 0.94407, 0.33922, -58.15%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.51015, 0.51015, 0.71425, 0.31206, -55.98%
Time spent: 35.78s
- Epoch 014, ExpID 17642
Train - Loss (one batch): 0.42630
Val - Loss, MSE, RMSE, MAE, MAPE: 0.89404, 0.89404, 0.94554, 0.33337, -54.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.51015, 0.51015, 0.71425, 0.31206, -55.98%
Time spent: 24.93s
- Epoch 015, ExpID 17642
Train - Loss (one batch): 0.08837
Val - Loss, MSE, RMSE, MAE, MAPE: 0.89155, 0.89155, 0.94422, 0.34619, -63.27%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 13, 0.51015, 0.51015, 0.71425, 0.31206, -55.98%
Time spent: 23.54s
- Epoch 016, ExpID 17642
Train - Loss (one batch): 0.27440
Val - Loss, MSE, RMSE, MAE, MAPE: 0.88999, 0.88999, 0.94339, 0.35404, -67.53%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.51101, 0.51101, 0.71485, 0.32716, -65.89%
Time spent: 35.00s
- Epoch 017, ExpID 17642
Train - Loss (one batch): 0.35893
Val - Loss, MSE, RMSE, MAE, MAPE: 0.89075, 0.89075, 0.94380, 0.33978, -58.56%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.51101, 0.51101, 0.71485, 0.32716, -65.89%
Time spent: 24.57s
- Epoch 018, ExpID 17642
Train - Loss (one batch): 0.10233
Val - Loss, MSE, RMSE, MAE, MAPE: 0.88988, 0.88988, 0.94334, 0.33393, -55.44%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 18, 0.50939, 0.50939, 0.71372, 0.30719, -53.57%
Time spent: 35.93s
- Epoch 019, ExpID 17642
Train - Loss (one batch): 0.21971
Val - Loss, MSE, RMSE, MAE, MAPE: 0.88956, 0.88956, 0.94316, 0.34195, -59.33%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 19, 0.50997, 0.50997, 0.71412, 0.31479, -57.64%
Time spent: 35.05s
- Epoch 020, ExpID 17642
Train - Loss (one batch): 0.26427
Val - Loss, MSE, RMSE, MAE, MAPE: 0.88909, 0.88909, 0.94291, 0.34243, -60.69%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.51078, 0.51078, 0.71469, 0.31585, -59.24%
Time spent: 34.85s
- Epoch 021, ExpID 17642
Train - Loss (one batch): 0.58801
Val - Loss, MSE, RMSE, MAE, MAPE: 0.89048, 0.89048, 0.94365, 0.34185, -60.77%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.51078, 0.51078, 0.71469, 0.31585, -59.24%
Time spent: 24.20s
- Epoch 022, ExpID 17642
Train - Loss (one batch): 0.21197
Val - Loss, MSE, RMSE, MAE, MAPE: 0.88991, 0.88991, 0.94335, 0.33367, -54.97%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.51078, 0.51078, 0.71469, 0.31585, -59.24%
Time spent: 25.78s
- Epoch 023, ExpID 17642
Train - Loss (one batch): 0.14396
Val - Loss, MSE, RMSE, MAE, MAPE: 0.89079, 0.89079, 0.94382, 0.34351, -62.08%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.51078, 0.51078, 0.71469, 0.31585, -59.24%
Time spent: 23.57s
- Epoch 024, ExpID 17642
Train - Loss (one batch): 1.26389
Val - Loss, MSE, RMSE, MAE, MAPE: 0.88874, 0.88874, 0.94273, 0.33893, -58.95%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 24, 0.51149, 0.51149, 0.71519, 0.31219, -57.61%
Time spent: 32.26s
- Epoch 025, ExpID 17642
Train - Loss (one batch): 1.42866
Val - Loss, MSE, RMSE, MAE, MAPE: 0.89032, 0.89032, 0.94357, 0.33794, -58.82%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 24, 0.51149, 0.51149, 0.71519, 0.31219, -57.61%
Time spent: 24.04s
- Epoch 026, ExpID 17642
Train - Loss (one batch): 0.70193
Val - Loss, MSE, RMSE, MAE, MAPE: 0.89072, 0.89072, 0.94378, 0.34574, -64.00%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 24, 0.51149, 0.51149, 0.71519, 0.31219, -57.61%
Time spent: 25.52s
- Epoch 027, ExpID 17642
Train - Loss (one batch): 0.23148
Val - Loss, MSE, RMSE, MAE, MAPE: 0.88966, 0.88966, 0.94322, 0.33395, -55.57%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 24, 0.51149, 0.51149, 0.71519, 0.31219, -57.61%
Time spent: 23.72s
- Epoch 028, ExpID 17642
Train - Loss (one batch): 0.34223
Val - Loss, MSE, RMSE, MAE, MAPE: 0.89204, 0.89204, 0.94448, 0.34374, -61.73%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 24, 0.51149, 0.51149, 0.71519, 0.31219, -57.61%
Time spent: 26.02s
- Epoch 029, ExpID 17642
Train - Loss (one batch): 0.77464
Val - Loss, MSE, RMSE, MAE, MAPE: 0.89008, 0.89008, 0.94344, 0.34269, -61.63%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 24, 0.51149, 0.51149, 0.71519, 0.31219, -57.61%
Time spent: 24.12s
- Epoch 030, ExpID 17642
Train - Loss (one batch): 0.16767
Val - Loss, MSE, RMSE, MAE, MAPE: 0.89302, 0.89302, 0.94500, 0.32903, -53.28%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 24, 0.51149, 0.51149, 0.71519, 0.31219, -57.61%
Time spent: 24.74s
- Epoch 031, ExpID 17642
Train - Loss (one batch): 0.18272
Val - Loss, MSE, RMSE, MAE, MAPE: 0.88812, 0.88812, 0.94240, 0.34057, -60.37%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 31, 0.51317, 0.51317, 0.71636, 0.31413, -59.32%
Time spent: 35.22s
- Epoch 032, ExpID 17642
Train - Loss (one batch): 0.14458
Val - Loss, MSE, RMSE, MAE, MAPE: 0.89144, 0.89144, 0.94416, 0.32742, -51.94%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 31, 0.51317, 0.51317, 0.71636, 0.31413, -59.32%
Time spent: 23.96s
- Epoch 033, ExpID 17642
Train - Loss (one batch): 0.38101
Val - Loss, MSE, RMSE, MAE, MAPE: 0.88866, 0.88866, 0.94269, 0.34915, -65.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 31, 0.51317, 0.51317, 0.71636, 0.31413, -59.32%
Time spent: 25.60s
- Epoch 034, ExpID 17642
Train - Loss (one batch): 0.45962
Val - Loss, MSE, RMSE, MAE, MAPE: 0.89030, 0.89030, 0.94356, 0.34127, -62.09%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 31, 0.51317, 0.51317, 0.71636, 0.31413, -59.32%
Time spent: 24.17s
- Epoch 035, ExpID 17642
Train - Loss (one batch): 0.11465
Val - Loss, MSE, RMSE, MAE, MAPE: 0.89193, 0.89193, 0.94442, 0.33460, -56.98%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 31, 0.51317, 0.51317, 0.71636, 0.31413, -59.32%
Time spent: 25.29s
- Epoch 036, ExpID 17642
Train - Loss (one batch): 0.38284
Val - Loss, MSE, RMSE, MAE, MAPE: 0.89256, 0.89256, 0.94475, 0.33061, -55.11%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 31, 0.51317, 0.51317, 0.71636, 0.31413, -59.32%
Time spent: 24.73s
- Epoch 037, ExpID 17642
Train - Loss (one batch): 0.37231
Val - Loss, MSE, RMSE, MAE, MAPE: 0.89170, 0.89170, 0.94430, 0.33449, -57.72%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 31, 0.51317, 0.51317, 0.71636, 0.31413, -59.32%
Time spent: 23.04s
- Epoch 038, ExpID 17642
Train - Loss (one batch): 0.54590
Val - Loss, MSE, RMSE, MAE, MAPE: 0.89305, 0.89305, 0.94501, 0.33893, -60.02%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 31, 0.51317, 0.51317, 0.71636, 0.31413, -59.32%
Time spent: 25.51s
- Epoch 039, ExpID 17642
Train - Loss (one batch): 0.11488
Val - Loss, MSE, RMSE, MAE, MAPE: 0.89296, 0.89296, 0.94497, 0.33269, -55.25%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 31, 0.51317, 0.51317, 0.71636, 0.31413, -59.32%
Time spent: 23.80s
- Epoch 040, ExpID 17642
Train - Loss (one batch): 0.38756
Val - Loss, MSE, RMSE, MAE, MAPE: 0.89143, 0.89143, 0.94416, 0.33588, -58.20%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 31, 0.51317, 0.51317, 0.71636, 0.31413, -59.32%
Time spent: 24.87s
- Epoch 041, ExpID 17642
Train - Loss (one batch): 0.28378
Val - Loss, MSE, RMSE, MAE, MAPE: 0.89335, 0.89335, 0.94517, 0.35234, -68.48%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 31, 0.51317, 0.51317, 0.71636, 0.31413, -59.32%
Time spent: 24.49s
- Epoch 042, ExpID 17642
Train - Loss (one batch): 0.41833
Val - Loss, MSE, RMSE, MAE, MAPE: 0.89515, 0.89515, 0.94612, 0.33710, -58.59%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 31, 0.51317, 0.51317, 0.71636, 0.31413, -59.32%
Time spent: 25.55s
- Epoch 043, ExpID 17642
Train - Loss (one batch): 0.57259
Val - Loss, MSE, RMSE, MAE, MAPE: 0.89503, 0.89503, 0.94606, 0.33779, -59.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 31, 0.51317, 0.51317, 0.71636, 0.31413, -59.32%
Time spent: 24.17s
- Epoch 044, ExpID 17642
Train - Loss (one batch): 1.25078
Val - Loss, MSE, RMSE, MAE, MAPE: 0.89547, 0.89547, 0.94629, 0.33862, -60.82%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 31, 0.51317, 0.51317, 0.71636, 0.31413, -59.32%
Time spent: 24.22s
- Epoch 045, ExpID 17642
Train - Loss (one batch): 0.51708
Val - Loss, MSE, RMSE, MAE, MAPE: 0.89621, 0.89621, 0.94668, 0.35076, -66.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 31, 0.51317, 0.51317, 0.71636, 0.31413, -59.32%
Time spent: 23.46s
- Epoch 046, ExpID 17642
Train - Loss (one batch): 0.65454
Val - Loss, MSE, RMSE, MAE, MAPE: 0.89452, 0.89452, 0.94579, 0.33580, -57.36%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 31, 0.51317, 0.51317, 0.71636, 0.31413, -59.32%
Time spent: 23.39s
