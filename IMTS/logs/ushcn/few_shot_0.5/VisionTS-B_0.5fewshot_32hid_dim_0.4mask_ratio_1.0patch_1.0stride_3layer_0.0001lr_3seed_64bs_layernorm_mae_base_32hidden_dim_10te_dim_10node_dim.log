/root/lvm4-ts/IMTS/run_models.py
2025-01-25 02:54:12
run_models.py --model VisionTS-B --dataset ushcn --state def --history 24 --patience 15 --batch_size 64 --lr 1e-4 --patch_size 1 --stride 1 --nhead 1 --tf_layer 1 --nlayer 3 --te_dim 10 --node_dim 10 --hid_dim 32 --mask_ratio 0.4 --train_mode fine-tune --finetune_type norm --pretrain_weights_dir /root/lvm4-ts/IMTS/logs/ushcn/fewshot_pretrain/pretrain_weights/Exp95350_VisionTS-B_hid_dim32_te_dim10_node_dim10_mask_ratio0.4_stride1.0_patchsize1.0_seed1_nlayer3_best.pth --few_shot_ratio 0.5 --seed 3 --gpu 3 --log_dir few_shot_0.5
Namespace(state='def', n=100000000, hop=1, nhead=1, tf_layer=1, nlayer=3, epoch=1000, patience=15, history=24, patch_size=1.0, stride=1.0, logmode='a', lr=0.0001, w_decay=0.0, batch_size=64, load=None, seed=3, dataset='ushcn', log_dir='few_shot_0.5', pretrain_weights_dir='/root/lvm4-ts/IMTS/logs/ushcn/fewshot_pretrain/pretrain_weights/Exp95350_VisionTS-B_hid_dim32_te_dim10_node_dim10_mask_ratio0.4_stride1.0_patchsize1.0_seed1_nlayer3_best.pth', quantization=0.0, model='VisionTS-B', mask_flag=False, hid_dim=32, te_dim=10, node_dim=10, gpu='3', log_suffix='', periodicity=None, mask_ratio=0.4, train_mode='fine-tune', TTT=False, ttt_iter=None, ttt_lr=None, apply_lora=False, lora_r=8, lora_alpha=1, lora_dropout=0.0, merge_weights=False, finetune_type='norm', encoder_only=False, few_shot_ratio=0.5, npatch=24, world_size=1, device=device(type='cuda'), ft_type='full', arch='mae_base', vm_pretrained=False, vm_ckpt='./ckpt/', interpolation='bilinear', norm_const=0.4, align_const=0.4, grid_method='linear', if_patch=True, n_months=48, pred_window=1, npred_patch=1, ndim=5)
- Epoch 000, ExpID 50977
Train - Loss (one batch): 0.44239
Val - Loss, MSE, RMSE, MAE, MAPE: 0.72944, 0.72944, 0.85407, 0.31694, -51.17%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 0, 0.49473, 0.49473, 0.70337, 0.29292, -47.75%
Time spent: 119.98s
- Epoch 001, ExpID 50977
Train - Loss (one batch): 0.31314
Val - Loss, MSE, RMSE, MAE, MAPE: 0.71260, 0.71260, 0.84416, 0.32501, -56.14%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.49239, 0.49239, 0.70171, 0.30176, -52.67%
Time spent: 120.39s
- Epoch 002, ExpID 50977
Train - Loss (one batch): 0.30430
Val - Loss, MSE, RMSE, MAE, MAPE: 0.71593, 0.71593, 0.84613, 0.32418, -57.66%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 1, 0.49239, 0.49239, 0.70171, 0.30176, -52.67%
Time spent: 110.76s
- Epoch 003, ExpID 50977
Train - Loss (one batch): 0.20316
Val - Loss, MSE, RMSE, MAE, MAPE: 0.70540, 0.70540, 0.83988, 0.32996, -61.23%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 3, 0.49093, 0.49093, 0.70066, 0.30607, -57.01%
Time spent: 119.95s
- Epoch 004, ExpID 50977
Train - Loss (one batch): 0.19829
Val - Loss, MSE, RMSE, MAE, MAPE: 0.69389, 0.69389, 0.83300, 0.32089, -56.26%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.48804, 0.48804, 0.69860, 0.29695, -52.14%
Time spent: 120.54s
- Epoch 005, ExpID 50977
Train - Loss (one batch): 0.43151
Val - Loss, MSE, RMSE, MAE, MAPE: 0.69928, 0.69928, 0.83623, 0.32775, -59.95%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 4, 0.48804, 0.48804, 0.69860, 0.29695, -52.14%
Time spent: 110.92s
- Epoch 006, ExpID 50977
Train - Loss (one batch): 0.23549
Val - Loss, MSE, RMSE, MAE, MAPE: 0.69296, 0.69296, 0.83244, 0.31276, -49.93%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 6, 0.48775, 0.48775, 0.69839, 0.28929, -46.26%
Time spent: 121.78s
- Epoch 007, ExpID 50977
Train - Loss (one batch): 0.15369
Val - Loss, MSE, RMSE, MAE, MAPE: 0.68596, 0.68596, 0.82823, 0.32239, -56.89%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 7, 0.48795, 0.48795, 0.69854, 0.29966, -53.53%
Time spent: 119.24s
- Epoch 008, ExpID 50977
Train - Loss (one batch): 0.31039
Val - Loss, MSE, RMSE, MAE, MAPE: 0.67322, 0.67322, 0.82050, 0.32559, -60.34%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 8, 0.48757, 0.48757, 0.69826, 0.30302, -56.26%
Time spent: 118.81s
- Epoch 009, ExpID 50977
Train - Loss (one batch): 0.13726
Val - Loss, MSE, RMSE, MAE, MAPE: 0.67638, 0.67638, 0.82242, 0.31918, -56.97%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 8, 0.48757, 0.48757, 0.69826, 0.30302, -56.26%
Time spent: 109.91s
- Epoch 010, ExpID 50977
Train - Loss (one batch): 0.22328
Val - Loss, MSE, RMSE, MAE, MAPE: 0.66566, 0.66566, 0.81588, 0.31814, -56.46%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.48662, 0.48662, 0.69758, 0.29589, -52.78%
Time spent: 119.20s
- Epoch 011, ExpID 50977
Train - Loss (one batch): 0.77009
Val - Loss, MSE, RMSE, MAE, MAPE: 0.67439, 0.67439, 0.82121, 0.31618, -51.90%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.48662, 0.48662, 0.69758, 0.29589, -52.78%
Time spent: 109.75s
- Epoch 012, ExpID 50977
Train - Loss (one batch): 0.19282
Val - Loss, MSE, RMSE, MAE, MAPE: 0.67343, 0.67343, 0.82063, 0.32339, -58.21%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.48662, 0.48662, 0.69758, 0.29589, -52.78%
Time spent: 108.98s
- Epoch 013, ExpID 50977
Train - Loss (one batch): 0.17250
Val - Loss, MSE, RMSE, MAE, MAPE: 0.67200, 0.67200, 0.81975, 0.31548, -53.76%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 10, 0.48662, 0.48662, 0.69758, 0.29589, -52.78%
Time spent: 113.04s
- Epoch 014, ExpID 50977
Train - Loss (one batch): 0.24592
Val - Loss, MSE, RMSE, MAE, MAPE: 0.66261, 0.66261, 0.81401, 0.32239, -58.34%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 14, 0.48493, 0.48493, 0.69637, 0.30054, -55.40%
Time spent: 119.22s
- Epoch 015, ExpID 50977
Train - Loss (one batch): 0.24864
Val - Loss, MSE, RMSE, MAE, MAPE: 0.66246, 0.66246, 0.81391, 0.32106, -55.54%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 15, 0.48525, 0.48525, 0.69660, 0.29917, -52.47%
Time spent: 116.90s
- Epoch 016, ExpID 50977
Train - Loss (one batch): 0.25775
Val - Loss, MSE, RMSE, MAE, MAPE: 0.65997, 0.65997, 0.81238, 0.32499, -60.25%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 16, 0.48506, 0.48506, 0.69646, 0.30345, -56.94%
Time spent: 119.75s
- Epoch 017, ExpID 50977
Train - Loss (one batch): 1.07262
Val - Loss, MSE, RMSE, MAE, MAPE: 0.64874, 0.64874, 0.80545, 0.32816, -61.29%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 17, 0.48535, 0.48535, 0.69667, 0.30678, -58.04%
Time spent: 119.46s
- Epoch 018, ExpID 50977
Train - Loss (one batch): 0.18793
Val - Loss, MSE, RMSE, MAE, MAPE: 0.64848, 0.64848, 0.80528, 0.31409, -52.54%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 18, 0.48433, 0.48433, 0.69594, 0.29235, -49.20%
Time spent: 122.09s
- Epoch 019, ExpID 50977
Train - Loss (one batch): 0.19199
Val - Loss, MSE, RMSE, MAE, MAPE: 0.65550, 0.65550, 0.80963, 0.33722, -68.21%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 18, 0.48433, 0.48433, 0.69594, 0.29235, -49.20%
Time spent: 111.44s
- Epoch 020, ExpID 50977
Train - Loss (one batch): 0.51510
Val - Loss, MSE, RMSE, MAE, MAPE: 0.64579, 0.64579, 0.80361, 0.31755, -54.40%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 20, 0.48408, 0.48408, 0.69576, 0.29561, -51.09%
Time spent: 120.44s
- Epoch 021, ExpID 50977
Train - Loss (one batch): 1.08284
Val - Loss, MSE, RMSE, MAE, MAPE: 0.64057, 0.64057, 0.80036, 0.31266, -52.99%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 21, 0.48401, 0.48401, 0.69571, 0.29116, -49.64%
Time spent: 119.80s
- Epoch 022, ExpID 50977
Train - Loss (one batch): 0.14853
Val - Loss, MSE, RMSE, MAE, MAPE: 0.63462, 0.63462, 0.79663, 0.31528, -53.29%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 22, 0.48478, 0.48478, 0.69626, 0.29432, -49.95%
Time spent: 118.68s
- Epoch 023, ExpID 50977
Train - Loss (one batch): 0.42327
Val - Loss, MSE, RMSE, MAE, MAPE: 0.63861, 0.63861, 0.79913, 0.31463, -53.56%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 22, 0.48478, 0.48478, 0.69626, 0.29432, -49.95%
Time spent: 110.27s
- Epoch 024, ExpID 50977
Train - Loss (one batch): 0.93730
Val - Loss, MSE, RMSE, MAE, MAPE: 0.64329, 0.64329, 0.80205, 0.32811, -63.57%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 22, 0.48478, 0.48478, 0.69626, 0.29432, -49.95%
Time spent: 107.68s
- Epoch 025, ExpID 50977
Train - Loss (one batch): 0.20580
Val - Loss, MSE, RMSE, MAE, MAPE: 0.63766, 0.63766, 0.79853, 0.31157, -51.48%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 22, 0.48478, 0.48478, 0.69626, 0.29432, -49.95%
Time spent: 108.71s
- Epoch 026, ExpID 50977
Train - Loss (one batch): 0.12237
Val - Loss, MSE, RMSE, MAE, MAPE: 0.63543, 0.63543, 0.79714, 0.32084, -57.26%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 22, 0.48478, 0.48478, 0.69626, 0.29432, -49.95%
Time spent: 109.79s
- Epoch 027, ExpID 50977
Train - Loss (one batch): 0.68758
Val - Loss, MSE, RMSE, MAE, MAPE: 0.64630, 0.64630, 0.80393, 0.31390, -53.83%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 22, 0.48478, 0.48478, 0.69626, 0.29432, -49.95%
Time spent: 108.77s
- Epoch 028, ExpID 50977
Train - Loss (one batch): 0.19226
Val - Loss, MSE, RMSE, MAE, MAPE: 0.63167, 0.63167, 0.79478, 0.31223, -54.10%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 28, 0.48458, 0.48458, 0.69612, 0.29163, -50.72%
Time spent: 117.99s
- Epoch 029, ExpID 50977
Train - Loss (one batch): 0.41197
Val - Loss, MSE, RMSE, MAE, MAPE: 0.63753, 0.63753, 0.79845, 0.30712, -48.29%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 28, 0.48458, 0.48458, 0.69612, 0.29163, -50.72%
Time spent: 111.04s
- Epoch 030, ExpID 50977
Train - Loss (one batch): 0.51153
Val - Loss, MSE, RMSE, MAE, MAPE: 0.63575, 0.63575, 0.79734, 0.32757, -64.08%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 28, 0.48458, 0.48458, 0.69612, 0.29163, -50.72%
Time spent: 110.01s
- Epoch 031, ExpID 50977
Train - Loss (one batch): 0.18523
Val - Loss, MSE, RMSE, MAE, MAPE: 0.64245, 0.64245, 0.80153, 0.30457, -48.00%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 28, 0.48458, 0.48458, 0.69612, 0.29163, -50.72%
Time spent: 109.16s
- Epoch 032, ExpID 50977
Train - Loss (one batch): 0.27714
Val - Loss, MSE, RMSE, MAE, MAPE: 0.63597, 0.63597, 0.79748, 0.31755, -58.20%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 28, 0.48458, 0.48458, 0.69612, 0.29163, -50.72%
Time spent: 108.65s
- Epoch 033, ExpID 50977
Train - Loss (one batch): 0.28911
Val - Loss, MSE, RMSE, MAE, MAPE: 0.63261, 0.63261, 0.79537, 0.31208, -54.71%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 28, 0.48458, 0.48458, 0.69612, 0.29163, -50.72%
Time spent: 111.62s
- Epoch 034, ExpID 50977
Train - Loss (one batch): 0.53309
Val - Loss, MSE, RMSE, MAE, MAPE: 0.63288, 0.63288, 0.79554, 0.32047, -55.94%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 28, 0.48458, 0.48458, 0.69612, 0.29163, -50.72%
Time spent: 109.83s
- Epoch 035, ExpID 50977
Train - Loss (one batch): 0.63187
Val - Loss, MSE, RMSE, MAE, MAPE: 0.63586, 0.63586, 0.79741, 0.31441, -52.24%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 28, 0.48458, 0.48458, 0.69612, 0.29163, -50.72%
Time spent: 111.55s
- Epoch 036, ExpID 50977
Train - Loss (one batch): 0.66347
Val - Loss, MSE, RMSE, MAE, MAPE: 0.64389, 0.64389, 0.80242, 0.31406, -54.58%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 28, 0.48458, 0.48458, 0.69612, 0.29163, -50.72%
Time spent: 110.72s
- Epoch 037, ExpID 50977
Train - Loss (one batch): 0.28534
Val - Loss, MSE, RMSE, MAE, MAPE: 0.63371, 0.63371, 0.79606, 0.31948, -58.14%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 28, 0.48458, 0.48458, 0.69612, 0.29163, -50.72%
Time spent: 111.02s
- Epoch 038, ExpID 50977
Train - Loss (one batch): 0.34402
Val - Loss, MSE, RMSE, MAE, MAPE: 0.63274, 0.63274, 0.79545, 0.32212, -59.94%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 28, 0.48458, 0.48458, 0.69612, 0.29163, -50.72%
Time spent: 111.22s
- Epoch 039, ExpID 50977
Train - Loss (one batch): 0.39799
Val - Loss, MSE, RMSE, MAE, MAPE: 0.63605, 0.63605, 0.79753, 0.30877, -51.11%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 28, 0.48458, 0.48458, 0.69612, 0.29163, -50.72%
Time spent: 110.34s
- Epoch 040, ExpID 50977
Train - Loss (one batch): 0.19811
Val - Loss, MSE, RMSE, MAE, MAPE: 0.63429, 0.63429, 0.79642, 0.30998, -51.32%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 28, 0.48458, 0.48458, 0.69612, 0.29163, -50.72%
Time spent: 110.27s
- Epoch 041, ExpID 50977
Train - Loss (one batch): 0.42756
Val - Loss, MSE, RMSE, MAE, MAPE: 0.63561, 0.63561, 0.79725, 0.31443, -55.52%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 28, 0.48458, 0.48458, 0.69612, 0.29163, -50.72%
Time spent: 111.61s
- Epoch 042, ExpID 50977
Train - Loss (one batch): 0.79022
Val - Loss, MSE, RMSE, MAE, MAPE: 0.63598, 0.63598, 0.79748, 0.32299, -60.30%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 28, 0.48458, 0.48458, 0.69612, 0.29163, -50.72%
Time spent: 109.70s
- Epoch 043, ExpID 50977
Train - Loss (one batch): 1.00848
Val - Loss, MSE, RMSE, MAE, MAPE: 0.63511, 0.63511, 0.79694, 0.31637, -56.42%
Test - Best epoch, Loss, MSE, RMSE, MAE, MAPE: 28, 0.48458, 0.48458, 0.69612, 0.29163, -50.72%
Time spent: 112.73s
